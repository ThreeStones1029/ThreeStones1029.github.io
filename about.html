---
layout: page
title: "About"
description: "Hey, this is ThreeStones1029."
header-img: "img/about_bg.jpg"
---

<!-- Language Selector -->
<select class="sel-lang" onchange= "onLanChange(this.options[this.options.selectedIndex].value)">
    <option value="0" selected> 中文 Chinese </option>
    <option value="1"> 英文 English </option>
</select> 

<!-- Chinese Version -->
<div class="zh post-container">

    <!--copied from markdown -->
    <blockquote><p>冰冻三尺 非一日之寒<br>
    积土成山 非斯须之作</p></blockquote>

    <p>我是<strong>帅磊</strong>，本硕均在<a href="https://www.hhu.edu.cn/">河海大学</a>，目前河海大学信息工程学院电子信息专业研三在读。</p>

    <p>我的主要工作是在蒋俊锋教授的指导下进行医学图像处理。我参与了常州市图形与骨科植入物数字技术重点实验室的多个项目和任务。我的工作涉及目标检测、图像分割、关键点识别和3D/2D配准。</p>

    <p>我的GitHub主页<a href="https://github.com/ThreeStones1029">👉GitHub·ThreeStones</a> 与 CSDN主页<a href="https://blog.csdn.net/SL1029_?spm=1000.2115.3001.5343">👉SL1029</a>。</p>

    <h5>最新</h5>

    <ul>

        <li> 2024.10.14 论文《ABLSpineLevelCheck: Localization of Vertebral Levels on Fluoroscopy via Semi-supervised Abductive Learning》被<strong>BIBM2024</strong>接收为short paper（接收率：21%）。</li> 

    </ul>

    <h5>主要项目</h5>

    <ul>
        <li>2024.04-至今 <strong>基于对比学习的术中X线片骨折识别</strong></li> 
        <li>2023.08-2024.04 <strong>基于溯因学习的术中X线片椎骨识别(BIBM2024)</strong></li>
        <div>
            <img src="https://cdn.jsdelivr.net/gh/ThreeStones1029/blogimages/img/%E4%B8%AD%E6%96%87%E6%B5%81%E7%A8%8B.png" alt="Description of the first image" style="width:500px;height:auto; display:inline-block;">
        </div>
        <p style="text-align: justify; text-justify: inter-ideograph;">
            深度学习在x射线图像中的椎骨定位方面显示出了良好的效果，尽管它在成分泛化、数据效率和可解释性方面存在不足。为了解决这个问题，我们引入了一种溯因学习机制，属于神经符号范式。
            最初，未注释的脊柱透视图像由神经网络推理，以推断椎体定位的伪标签。随后，这些伪标签通过由一阶逻辑子句组成的知识库进行溯因推理。然后利用推理的结果对网络进行再训练。
            此外，我们提出了一种集成技术，将椎体语义检测与实例检测相结合。为了进一步提高性能，我们合成了一个数据集，并对BUU数据集进行了注释，用于网络预训练。消融研究证实了我们的方法中提出的组件的有效性。
            此外，对比分析表明，我们的方法显着超越了领先的目标检测算法，以最少的注释表现出卓越的性能。
        </p>
        <li>2023.02-2023.07 <strong>脊柱CT椎骨分割与定位</strong></li>
        <div>
            <img src="https://cdn.jsdelivr.net/gh/ThreeStones1029/blogimages/img/795b8e24c2a739450024cc895067a7e.png" alt="Description of the first image" style="width:800px;height:auto; display:inline-block;">
        </div>
    </ul>

    <h5>其他项目</h5>
    <ul>
        <li>2024.01 <strong>脊柱DRR生成与标注</strong></li>
        <a href="https://github.com/ThreeStones1029/drr_utils"> python代码</a> 和 <a href="https://github.com/ThreeStones1029/drr_utils_cpp"> C++代码 </a>
        <div>
            <img src="https://cdn.jsdelivr.net/gh/ThreeStones1029/blogimages/img/drr_utils.png" alt="Description of the first image" style="width:500px;height:auto; display:inline-block;">
        </div>
        <div>
            <img src="https://cdn.jsdelivr.net/gh/ThreeStones1029/blogimages/img/87ba5c6d82449c55216500d72d935d57.JPG" alt="Description of the first image" style="width:310px;height:auto; display:inline-block; margin-right:10px;">
            <img src="https://cdn.jsdelivr.net/gh/ThreeStones1029/blogimages/img/7133247c4a632362151af6f9a458f1c0.JPG" alt="Description of the second image" style="width:300px;height:auto; display:inline-block;">
        </div>
        将脊柱CT分割算法分割的mask结果，利用ITK投影，根据mask的边界得到水平矩形框以及旋转矩形框，同时得到投影的mask作为分割标注。
        <li>2023.11-2023.12 <strong>基于nnunet的椎骨分割</strong></li> 
        <div>
            <img src="https://cdn.jsdelivr.net/gh/ThreeStones1029/blogimages/img/nnunet_seg.png" alt="Description of the first image" style="width:800px;height:auto; display:inline-block;">
        </div>
        首先预测对椎体进行语义识别，根据检测框裁剪出每一节椎体，然后使用nnunet进行0,1分割得到每一节的分割结果。
        <li>2023.07-2023.08 <strong>基于HRNet的椎骨关键点检测</strong></li> 
        数据标注
        <div>
            <img src="https://cdn.jsdelivr.net/gh/ThreeStones1029/blogimages/img/$OC5X%5B7XAO6SHURBG86%7B2ML.png" alt="Description of the first image" style="width:400px;height:auto; display:inline-block;">
        </div>
        数据标注通过open3d将椎体上的3维标志点椎体上平面中心、椎体下平面中心和左右椎弓根四个点投影到DRR上。
        结果
        <div>
            <img src="https://cdn.jsdelivr.net/gh/ThreeStones1029/blogimages/img/HRNet_AP.jpg" alt="Description of the first image" style="width:300px;height:auto; display:inline-block; margin-right:10px;">
            <img src="https://cdn.jsdelivr.net/gh/ThreeStones1029/blogimages/img/))T8%5B%5B4BDC1GRR%7DZ@AQ$%60CK.png" alt="Description of the second image" style="width:300px;height:auto; display:inline-block;">
        </div>

    </ul>
    <p></p>
</div>

<!-- English Version -->
<div class="en post-container">
    <blockquote><p>Frozen three feet is not a day's cold <br>
    Making mountains from mounds is not done in a short time</p></blockquote>

    <p>Hi, I am <strong>Shuai Lei</strong>，Both my master's and master's degrees are in Hohai University. At present, I am a research junior student in the School of Information Engineering, Hohai University.</p>
    
    <p>I primarily worked under the guidance of Prof. JunFeng Jiang on medical image processing.  
       I participated in several projects and tasks at the ChangZhou Key Laboratory of Digital Technology on Graphics and Orthopaedic implants.  
       My work involved object detection、image segmentation、keypoints recognition and 3D/2D registration.</p>
    <p>My github home page<a href="https://github.com/ThreeStones1029">👉GitHub·ThreeStones</a> and CSDN home page<a href="https://blog.csdn.net/SL1029_?spm=1000.2115.3001.5343">👉SL1029</a>。</p>
    
    <h5>News</h5>

    <ul>

        <li> 2024.10.14 The paper《ABLSpineLevelCheck: Localization of Vertebral Levels on Fluoroscopy via Semi-supervised Abductive Learning》was accepted by <strong>BIBM2024</strong> as a short paper(Acceptance rate:21%).</li> 

    </ul>
    
    <h5>Main Projects</h5>

    <ul>
        <li>2024.04-now <strong>Contrastive Learning for Fracture recognition in Intraoperative Radiographs</strong></li> 
        <li>2023.08-2024.04 <strong>Vertebrae Recognition on Intraoperative Radiographs Using Abductive Learning(BIBM2024)</strong></li>
        <div>
            <img src="https://cdn.jsdelivr.net/gh/ThreeStones1029/blogimages/img/%E5%9F%BA%E4%BA%8E%E6%BA%AF%E5%9B%A0%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%9C%AF%E4%B8%ADX%E7%BA%BF%E7%89%87%E6%A4%8E%E9%AA%A8%E8%AF%86%E5%88%AB%E8%8B%B1%E6%96%87%E6%B5%81%E7%A8%8B.png" alt="Description of the first image" style="width:500px;height:auto; display:inline-block;">
        </div>
        <p style="text-align: justify;">
            Deep learning has demonstrated promising efficacy in the localization of vertebrae within X-ray imagery, although it is recognized for its deficiencies in compositional generalization, 
            data efficiency, and interpretability. To address this issue, we introduce an abductive learning mechanism, situated within the neuro-symbolic paradigm, tailored for semi-supervised vertebral localization. 
            Initially, unannotated spinal fluoroscopic images are processed by the networks to infer pseudo-labels for vertebra localization. 
            Subsequently, these pseudo-labels undergo abductive reasoning via a knowledge base comprised of first-order logical clauses. The networks are then retrained utilizing the abducted outcomes. 
            Additionally, we propose an ensemble technique that amalgamates semantic detection of vertebral levels with instance detection. 
            To further augment performance, we have synthesized a dataset and annotated the BUU dataset for network pretraining. Ablation studies validate the efficacy of the proposed components in our methodology. 
            Furthermore, comparative analyses reveal that our approach significantly surpasses leading object detection algorithms, exhibiting superior performance with minimal annotations.
        </p>
        <li>2023.02-2023.07 <strong>Vertebral segmentation and localization in spine CT</strong></li>
    </ul>

    <h5>Other Projects</h5>
    <ul>
        <li>2024.01 <strong>Spine DRR generation and annotation</strong></li>
        <a href="https://github.com/ThreeStones1029/drr_utils"> python code</a> 和 <a href="https://github.com/ThreeStones1029/drr_utils_cpp"> C++ code </a>
        <div>
            <img src="https://cdn.jsdelivr.net/gh/ThreeStones1029/blogimages/img/drr_utils.png" alt="Description of the first image" style="width:500px;height:auto; display:inline-block;">
        </div>
        The ITK projection is used to obtain the horizontal rectangular box and the rotating rectangular box according to the boundary of the mask. At the same time, the projected mask is obtained as the segmentation label.
        <li>2023.11-2023.12 <strong>Vertebra segmentation based on nnunet</strong></li> 
        <div>
            <img src="https://cdn.jsdelivr.net/gh/ThreeStones1029/blogimages/img/%E5%9F%BA%E4%BA%8Ennunet%E7%9A%84%E6%A4%8E%E9%AA%A8%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E8%8B%B1%E6%96%87%E6%B5%81%E7%A8%8B.png" alt="Description of the first image" style="width:800px;height:auto; display:inline-block;">
        </div>
        Firstly, the semantic recognition of the vertebrae is performed, and each vertebra is cut out according to the detection box. Then nnunet is used to perform 0,1 segmentation to obtain the segmentation results of each segment.
        <li>2023.07-2023.08 <strong>Keypoint detection of vertebrae based on HRNet</strong></li> 
        Data annotation
        <div>
            <img src="https://cdn.jsdelivr.net/gh/ThreeStones1029/blogimages/img/$OC5X%5B7XAO6SHURBG86%7B2ML.png" alt="Description of the first image" style="width:400px;height:auto; display:inline-block;">
        </div>
        Data annotation was performed by open3d to project four points on the vertebral body, including the center of the upper plane of the vertebral body, the center of the lower plane of the vertebral body, and the left and right pedicles, onto the DRR.
        Results
        <div>
            <img src="https://cdn.jsdelivr.net/gh/ThreeStones1029/blogimages/img/HRNet_AP.jpg" alt="Description of the first image" style="width:300px;height:auto; display:inline-block; margin-right:10px;">
            <img src="https://cdn.jsdelivr.net/gh/ThreeStones1029/blogimages/img/))T8%5B%5B4BDC1GRR%7DZ@AQ$%60CK.png" alt="Description of the second image" style="width:300px;height:auto; display:inline-block;">
        </div>

    </ul>
    

    
</div> 

<!-- Handle Language Change -->
<script type="text/javascript">
    // get nodes
    var $zh = document.querySelector(".zh");
    var $en = document.querySelector(".en");
    var $select = document.querySelector("select");

    // bind hashchange event
    window.addEventListener('hashchange', _render);

    // handle render
    function _render(){
        var _hash = window.location.hash;
        // en
        if(_hash == "#en"){
            $select.selectedIndex = 1;
            $en.style.display = "block";
            $zh.style.display = "none";
        // zh by default
        }else{
            // not trigger onChange, otherwise cause a loop call.
            $select.selectedIndex = 0;
            $zh.style.display = "block";
            $en.style.display = "none";
        }
    }

    // handle select change
    function onLanChange(index){
        if(index == 0){
            window.location.hash = "#zh"
        }else{
            window.location.hash = "#en"
        }
    }

    // init
    _render();
</script>

<!-- Gitalk 评论 start  -->
{% if site.gitalk.enable %}
<!-- Gitalk link  -->
<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script>

<div id="gitalk-container"></div>
    <script type="text/javascript">
    var gitalk = new Gitalk({
    clientID: '{{site.gitalk.clientID}}',
    clientSecret: '{{site.gitalk.clientSecret}}',
    repo: '{{site.gitalk.repo}}',
    owner: '{{site.gitalk.owner}}',
    admin: ['{{site.gitalk.admin}}'],
    distractionFreeMode: {{site.gitalk.distractionFreeMode}},
    id: 'about',
    });
    gitalk.render('gitalk-container');
</script>
{% endif %}
<!-- Gitalk end -->

 <!-- disqus 评论框 start  -->
{% if site.disqus.enable %}

<div class="comment">
    <div id="disqus_thread" class="disqus-thread">
    </div>
</div>
<!-- disqus 评论框 end -->

<!-- disqus 公共JS代码 start (一个网页只需插入一次) -->
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = "{{site.disqus.username}}";
    var disqus_identifier = "{{site.disqus.username}}/{{page.url}}";
    var disqus_url = "{{site.url}}{{page.url}}";

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<!-- disqus 公共JS代码 end -->
{% endif %}
